density:
  basis: linear
  gradient scale length: 400.0um
  max: 0.28
  min: 0.18
  noise:
    max: 1.0e-09
    min: 1.0e-10
    type: uniform
    
drivers:
  E0:
    delta_omega_max: 0.005
    envelope:
      tc: 200.25ps
      tr: 0.1ps
      tw: 4000ps
      xc: 50um
      xr: 0.2um
      xw: 1000um
      yc: 50um
      yr: 0.2um
      yw: 1000um
    num_colors: 32
    shape: smooth_arbitrary
    params:
      amplitudes: 
        init: uniform # uniform, random
        learned: true
        activation: log
        bounded: false
      phases:
        init: random # random, seed-###
        learned: true
        seed: 42

grid:
  boundary_abs_coeff: 1
  boundary_width: 3.0um
  dt: 0.007ps
  dx: 40nm
  low_pass_filter: 0.5
  tmax: 100ps
  tmin: 0.0ns
  ymax: 6um
  ymin: -6um

training data:
  num_temperatures: 16
  num_gradient_scale_lengths: 1

parsl:
  provider: gpu
  nodes: 4
  walltime: 12:00:00

mlflow:
  experiment: learn-tpd-100ps
  run: Te-avg-Ln200-smootharb-lr01

save:
  fields:
    t:
      dt: 10ps
      tmax: 100ps
      tmin: 0ps
    x:
      dx: 50nm
    y:
      dy: 50nm
solver: envelope-2d
terms:
  epw:
    hyperviscosity:
      order: 6
      coeff: 5.0e-4
    boundary:
      x: absorbing
      y: periodic
    damping:
      collisions: 0.1
      landau: true
    density_gradient: true
    linear: true
    source: 
      noise: true
      tpd: true
      srs: false
  zero_mask: true
units:
  atomic number: 40
  envelope density: 0.25
  ionization state: 6
  laser intensity: 7.0e14 W/cm^2
  laser_wavelength: 351nm
  reference electron temperature: 3200 eV
  reference ion temperature: 1000eV
opt:
  learning_rate: 0.1
  batch_size: 1
  decay_steps: 100000
  method: optax
  metric_time_in_ps: 98.5
  checkpoints_coeff: 2.5 # number of checkpoints = checkpoints_coeff * (sqrt(2 * (max_steps + 2048) + 0.25) - 1.5)
  # XLA cache cleanup interval (iterations for scipy, epochs for optax)
  # Helps prevent memory buildup during long optimization runs
  cache_cleanup_interval: 1
